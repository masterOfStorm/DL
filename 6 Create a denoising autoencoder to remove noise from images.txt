6: Create a denoising autoencoder to remove noise from images.

STEP #1: IMPORT LIBRARIES AND DATASET

import tensorflow as tf 
import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
import seaborn as sns 
import random 

(X_train, y_train), (X_test, y_test) = 
tf.keras.datasets.fashion_mnist.load_data()

plt.imshow(X_train[0], cmap="gray")
X_train.shape
X_test.shape

STEP #2: PERFORM DATA VISUALIZATION 

i = random.randint(1,60000) # select any random index from 1 to 
60,000 
plt.imshow( X_train[i] , cmap = 'gray')

label = y_train[i] 
label 

W_grid = 15 
L_grid = 15

fig, axes = plt.subplots(L_grid, W_grid, figsize = (17,17)) 
 
axes = axes.ravel()
n_training = len(X_train) 
for i in np.arange(0, W_grid * L_grid): 
    index = np.random.randint(0, n_training) 
    axes[i].imshow( X_train[index] ) 
    axes[i].set_title(y_train[index], fontsize = 8) 
    axes[i].axis('off') 
plt.subplots_adjust(hspace=0.4)

STEP #3: PERFORM DATA PREPROCESSING

X_train = X_train / 255 
X_test = X_test / 255

noise_factor = 0.3 
 
noise_dataset = [] 
 
for img in X_train: 
  noisy_image = img + noise_factor * np.random.randn(*img.shape) 
  noisy_image = np.clip(noisy_image, 0., 1.) 
  noise_dataset.append(noisy_image) 

noise_dataset = np.array(noise_dataset)
noise_dataset.shape 
plt.imshow(noise_dataset[22], cmap="gray") 
noise_test_set = [] 
for img in X_test: 
  noisy_image = img + noise_factor * np.random.randn(*img.shape) 
  noisy_image = np.clip(noisy_image, 0., 1.) 
  noise_test_set.append(noisy_image) 
   
noise_test_set = np.array(noise_test_set) 
noise_test_set.shape

STEP #4: BUILD AND TRAIN AUTOENCODER DEEP LEARNING MODEL 

autoencoder = tf.keras.models.Sequential() 
autoencoder.add(tf.keras.layers.Conv2D(filters=16, kernel_size=3, 
strides=2, padding="same", input_shape=(28, 28, 1))) 
autoencoder.add(tf.keras.layers.Conv2D(filters=8, kernel_size=3, 
strides=2, padding="same"))  
autoencoder.add(tf.keras.layers.Conv2D(filters=8, kernel_size=3, 
strides=1, padding="same")) 
autoencoder.add(tf.keras.layers.Conv2DTranspose(filters=16, 
kernel_size=3, strides=2, padding="same")) 
autoencoder.add(tf.keras.layers.Conv2DTranspose(filters=1, 
kernel_size=3, strides=2, activation='sigmoid', padding="same"))
autoencoder.compile(loss='binary_crossentropy', 
optimizer=tf.keras.optimizers.Adam(lr=0.001)) 
autoencoder.summary()
autoencoder.fit(noise_dataset.reshape(-1, 28, 28, 1),           
                X_train.reshape(-1, 28, 28, 1),  
                epochs=10,  
                batch_size=200,  
                validation_data=(noise_test_set.reshape(-1, 28, 28, 
1), X_test.reshape(-1, 28, 28, 1)))


STEP #5: EVALUATE TRAINED MODEL PERFORMANCE

evaluation = autoencoder.evaluate(noise_test_set.reshape(-1, 28, 28, 
1), X_test.reshape(-1, 28, 28, 1)) 
print('Test Accuracy : {:.3f}'.format(evaluation))
predicted = autoencoder.predict(noise_test_set[:10].reshape(-1, 28, 
28, 1)) 
predicted.shape
fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, 
sharey=True, figsize=(20,4)) 
for images, row in zip([noise_test_set[:10], predicted], axes): 
    for img, ax in zip(images, row): 
        ax.imshow(img.reshape((28, 28)), cmap='Greys_r') 
        ax.get_xaxis().set_visible(False) 
        ax.get_yaxis().set_visible(False) 