Bengali 1 

1st

Great! Here‚Äôs a step-by-step Python implementation plan using *TensorFlow/Keras* to build and evaluate your *Diabetes Risk Prediction System*, addressing each of your tasks:

---

## ‚úÖ Step-by-Step Implementation

### 1. *Load and Preprocess the Dataset*

We'll use the *Pima Indians Diabetes Dataset* (from Kaggle or sklearn.datasets).

python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import matplotlib.pyplot as plt
import tensorflow as tf

# Load dataset
data = pd.read_csv("diabetes.csv")  # Replace with your path

# Features & Target
X = data.drop("Outcome", axis=1)
y = data["Outcome"]

# Normalize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split data
X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)


---

### 2. *Define the Neural Network Architecture*

A simple feedforward network for binary classification:

python
def create_model(optimizer):
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(16, activation='relu', input_shape=(X.shape[1],)),
        tf.keras.layers.Dense(8, activation='relu'),
        tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification
    ])
    model.compile(optimizer=optimizer,
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model


---

### 3. *Train with Adam and RMSProp + Hyperparameter Tuning*

Experiment with different learning rates.

python
optimizers = {
    "Adam (0.001)": tf.keras.optimizers.Adam(learning_rate=0.001),
    "RMSProp (0.001)": tf.keras.optimizers.RMSprop(learning_rate=0.001),
    "Adam (0.0005)": tf.keras.optimizers.Adam(learning_rate=0.0005),
    "RMSProp (0.0005)": tf.keras.optimizers.RMSprop(learning_rate=0.0005)
}

history_dict = {}
results = {}

for name, optimizer in optimizers.items():
    print(f"Training with {name}")
    model = create_model(optimizer)
    history = model.fit(X_train, y_train, epochs=50, batch_size=16,
                        validation_data=(X_val, y_val), verbose=0)
    
    # Save training history
    history_dict[name] = history
    
    # Evaluate on test set
    y_pred = (model.predict(X_test) > 0.5).astype("int32")
    results[name] = {
        "accuracy": accuracy_score(y_test, y_pred),
        "precision": precision_score(y_test, y_pred),
        "recall": recall_score(y_test, y_pred),
        "f1": f1_score(y_test, y_pred),
        "auc": roc_auc_score(y_test, y_pred)
    }


---

### 4. *Plot Training History*

Loss and accuracy comparison.

python
for metric in ['loss', 'accuracy']:
    plt.figure(figsize=(10, 5))
    for name, history in history_dict.items():
        plt.plot(history.history[metric], label=f'{name} Train')
        plt.plot(history.history[f'val_{metric}'], linestyle='--', label=f'{name} Val')
    plt.title(f'{metric.title()} Comparison')
    plt.xlabel('Epochs')
    plt.ylabel(metric.title())
    plt.legend()
    plt.grid(True)
    plt.show()


---

### 5. *Compare Final Metrics*

python
import pandas as pd

metrics_df = pd.DataFrame(results).T
print("\nEvaluation Metrics Comparison:")
print(metrics_df.round(4))


---

### 6. *Analysis Criteria*

* *Convergence speed* ‚Üí Check training curves
* *Final accuracy & metrics* ‚Üí Refer to metrics_df
* *Stability* ‚Üí Smoothness/volatility in loss plots

---

Would you like:

* üìà Ready-made comparison graphs?
* üìÅ Help converting this into a Jupyter Notebook?
* üß† Model performance explanations?

Let me know, and I‚Äôll tailor the next steps accordingly.